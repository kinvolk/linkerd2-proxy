# Benchmark

The benchmark script applies HTTP, gRPC, and TCP workloads with
the benchmark utilities wrk2, strest-grpc, and iperf.
The script logs to files and generates a summary CSV with the
99th percentile latencies (or GBit/s for TCP).

You can read the summary file or the individual result files for
each run. The JSON files for HTTP/gRPC generated by fortio can
also be inspected as graphs with the fortio UI
(start in the profiling directory):

```
$ fortio report
# Now open http://localhost:8080/
```

Select one, two, or multiple data sets to compare the results.

## Compare the summary file of two branches

Two summary CSVs can be compared by plotting them as graphs:

```
$ cd profiling/
$ ./benchmark-cargo-test-fortio.sh ; git checkout master && ./benchmark-cargo-test-fortio.sh
$ ./plot.py summary.mybranch.2019Jun19_15h13m12s.txt summary.master.2019Jun19_15h34m26s.txt mybranch-vs-master-
$ eog mybranch-vs-master-*png
```

Consider to use `./plot.py --logy ...` if the difference between the values is too high to see the low values.

Another option is to quickly compare in textual form:
```
$ git diff --no-index --word-diff summary.mybranch.2019Jun19_15h13m12s.txt summary.master.2019Jun19_15h34m26s.txt
```

## Customize Parameters

The benchmark script takes the following environment variables to determine the test parameters.
When not provided they default to the values as listed here.

`TCP="1"`: Enable/disable TCP benchmark.

`HTTP="1"`: Enable/disable HTTP benchmark.

`GRPC="1"`: Enable/disable gRPC benchmark.

`ITERATIONS="1"`: The number of times a single HTTP/gRPC benchmark run is repeated to observe the maximal tail latency.

`DURATION="10s"`: Execution time for a single HTTP/gRPC benchmark run.

`CONNECTIONS="4"`: Number of concurrent TCP connections for HTTP/gRPC.

`GRPC_STREAMS="4"`: Number of HTTP/2 streams in a connection.

`HTTP_RPS="4000 7000"`: Different target HTTP req/s numbers as space-separated list. It may not be achieved if too high.
Please see the actual req/s in the log output.

`GRPC_RPS="4000 6000"`: As above but for gRPC.

`REQ_BODY_LEN="10 200"`: Length of the request body payload in byte as space-separated list.

`HIDE="1"`: Hide/show output of every command.
The output of each benchmark utility is stored to log files in any case.

Dummy values to illustrate usage for a quick test run:

```
$ ITERATIONS=2 DURATION=2s CONNECTIONS=2 GRPC_STREAMS=2 HTTP_RPS="100" GRPC_RPS="100 1000" REQ_BODY_LEN="100 8000" ./benchmark-cargo-test-fortio.sh
```

# Profiling

Profiling needs to have a build with debug symbols but optimizations.
The build script will generate such a binary but needs to be run
manually before the profiling if the source code changed.

The profiling happens while the benchmark workload is applied.

## Trace function calls with perf

Trace function call stacks (2000 per second) and generate flamegraphs:

```
$ ./profiling-build.sh # if needed
$ ./profiling-perf-fortio.sh
$ firefox/chrome flamegraph*svg  # view flamegraphs
```


## Trace memory allocations

Trace heap memory allocations and generate flamegraphs:

```
$ ./profiling-build.sh # if needed
$ ./profiling-heap-fortio.sh
$ firefox/chrome heap-flamegraph*svg
$ heaptrack -a â€¦.heaptrack.dat  # or view detailed report
```
